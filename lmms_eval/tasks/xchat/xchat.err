/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/seungonk/anaconda3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  _torch_pytree._register_pytree_node(
Traceback (most recent call last):
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1764, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/home/seungonk/anaconda3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/models/paligemma/modeling_paligemma.py", line 39, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py", line 10, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/seungonk/lmms-eval-mmllm/lmms_eval/tasks/xchat/response_gen_litellm.py", line 9, in <module>
    from transformers import AutoProcessor, LlavaForConditionalGeneration, LlavaNextForConditionalGeneration, PaliGemmaForConditionalGeneration, Blip2ForConditionalGeneration, Blip2Processor, AutoModelForCausalLM
  File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1755, in __getattr__
    value = getattr(module, name)
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1754, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1766, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.models.paligemma.modeling_paligemma because of the following error (look up to see its traceback):
/home/seungonk/anaconda3/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE
