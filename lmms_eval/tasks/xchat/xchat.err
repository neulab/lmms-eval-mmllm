/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.20s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.31it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s]
  0%|          | 0/50 [00:00<?, ?it/s]Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  2%|▏         | 1/50 [01:14<1:00:29, 74.06s/it]  4%|▍         | 2/50 [02:19<55:00, 68.76s/it]    6%|▌         | 3/50 [03:06<46:21, 59.19s/it]  8%|▊         | 4/50 [04:07<45:40, 59.58s/it] 10%|█         | 5/50 [04:40<37:44, 50.32s/it] 12%|█▏        | 6/50 [05:06<30:35, 41.72s/it] 14%|█▍        | 7/50 [05:30<25:53, 36.14s/it] 16%|█▌        | 8/50 [05:49<21:31, 30.75s/it] 18%|█▊        | 9/50 [06:19<20:52, 30.55s/it] 20%|██        | 10/50 [06:52<20:49, 31.23s/it] 22%|██▏       | 11/50 [07:20<19:37, 30.20s/it] 24%|██▍       | 12/50 [07:47<18:33, 29.30s/it] 26%|██▌       | 13/50 [08:01<15:08, 24.56s/it] 28%|██▊       | 14/50 [08:26<14:48, 24.69s/it] 30%|███       | 15/50 [09:05<16:54, 29.00s/it] 32%|███▏      | 16/50 [09:33<16:18, 28.78s/it] 34%|███▍      | 17/50 [10:47<23:12, 42.21s/it] 36%|███▌      | 18/50 [11:22<21:23, 40.12s/it] 38%|███▊      | 19/50 [11:59<20:18, 39.29s/it] 40%|████      | 20/50 [12:45<20:38, 41.28s/it] 42%|████▏     | 21/50 [13:49<23:10, 47.95s/it] 44%|████▍     | 22/50 [14:38<22:31, 48.28s/it] 46%|████▌     | 23/50 [15:18<20:35, 45.75s/it] 48%|████▊     | 24/50 [16:04<19:53, 45.92s/it] 50%|█████     | 25/50 [16:45<18:28, 44.34s/it] 52%|█████▏    | 26/50 [17:58<21:10, 52.93s/it] 54%|█████▍    | 27/50 [18:50<20:15, 52.87s/it] 56%|█████▌    | 28/50 [19:38<18:50, 51.40s/it] 58%|█████▊    | 29/50 [20:12<16:10, 46.23s/it] 60%|██████    | 30/50 [21:11<16:41, 50.05s/it] 62%|██████▏   | 31/50 [21:35<13:20, 42.12s/it] 64%|██████▍   | 32/50 [21:58<10:56, 36.45s/it] 66%|██████▌   | 33/50 [22:38<10:38, 37.58s/it] 68%|██████▊   | 34/50 [23:01<08:48, 33.06s/it] 70%|███████   | 35/50 [23:08<06:20, 25.38s/it] 72%|███████▏  | 36/50 [24:02<07:53, 33.79s/it] 74%|███████▍  | 37/50 [24:06<05:24, 24.98s/it] 76%|███████▌  | 38/50 [24:29<04:50, 24.21s/it] 78%|███████▊  | 39/50 [24:54<04:29, 24.50s/it] 80%|████████  | 40/50 [25:09<03:37, 21.74s/it] 82%|████████▏ | 41/50 [25:54<04:18, 28.75s/it] 84%|████████▍ | 42/50 [26:53<05:02, 37.85s/it] 86%|████████▌ | 43/50 [28:06<05:39, 48.45s/it] 88%|████████▊ | 44/50 [28:57<04:53, 48.95s/it] 90%|█████████ | 45/50 [29:48<04:08, 49.74s/it] 92%|█████████▏| 46/50 [30:02<02:35, 38.98s/it] 94%|█████████▍| 47/50 [30:54<02:08, 42.83s/it] 96%|█████████▌| 48/50 [31:41<01:28, 44.19s/it] 98%|█████████▊| 49/50 [32:35<00:47, 47.06s/it]100%|██████████| 50/50 [33:20<00:00, 46.39s/it]100%|██████████| 50/50 [33:20<00:00, 40.01s/it]
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.77it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]
  0%|          | 0/50 [00:00<?, ?it/s]Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  2%|▏         | 1/50 [00:50<41:02, 50.26s/it]  4%|▍         | 2/50 [01:09<25:24, 31.76s/it]  6%|▌         | 3/50 [02:20<39:06, 49.92s/it]  8%|▊         | 4/50 [03:01<35:32, 46.36s/it] 10%|█         | 5/50 [03:48<34:59, 46.66s/it] 12%|█▏        | 6/50 [04:01<25:54, 35.32s/it] 14%|█▍        | 7/50 [04:11<19:12, 26.81s/it] 16%|█▌        | 8/50 [04:31<17:17, 24.70s/it] 18%|█▊        | 9/50 [04:46<14:43, 21.56s/it] 20%|██        | 10/50 [05:08<14:27, 21.68s/it] 22%|██▏       | 11/50 [06:05<21:08, 32.52s/it] 24%|██▍       | 12/50 [07:18<28:29, 44.98s/it] 26%|██▌       | 13/50 [08:24<31:40, 51.35s/it] 28%|██▊       | 14/50 [09:28<33:06, 55.19s/it] 30%|███       | 15/50 [10:29<33:08, 56.81s/it] 32%|███▏      | 16/50 [11:32<33:15, 58.70s/it] 34%|███▍      | 17/50 [11:46<24:53, 45.25s/it] 36%|███▌      | 18/50 [12:06<20:08, 37.75s/it] 38%|███▊      | 19/50 [12:56<21:26, 41.49s/it] 40%|████      | 20/50 [13:32<19:52, 39.77s/it] 42%|████▏     | 21/50 [14:07<18:33, 38.41s/it] 44%|████▍     | 22/50 [14:22<14:34, 31.22s/it] 46%|████▌     | 23/50 [15:18<17:26, 38.76s/it] 48%|████▊     | 24/50 [15:41<14:45, 34.06s/it] 50%|█████     | 25/50 [16:19<14:35, 35.03s/it] 52%|█████▏    | 26/50 [17:08<15:43, 39.32s/it] 54%|█████▍    | 27/50 [18:22<19:08, 49.92s/it] 56%|█████▌    | 28/50 [19:23<19:28, 53.11s/it] 58%|█████▊    | 29/50 [19:53<16:10, 46.23s/it] 60%|██████    | 30/50 [20:51<16:31, 49.58s/it] 62%|██████▏   | 31/50 [21:17<13:27, 42.51s/it] 64%|██████▍   | 32/50 [21:53<12:10, 40.61s/it] 66%|██████▌   | 33/50 [22:33<11:25, 40.34s/it] 68%|██████▊   | 34/50 [22:49<08:50, 33.13s/it] 70%|███████   | 35/50 [23:22<08:19, 33.29s/it] 72%|███████▏  | 36/50 [24:34<10:24, 44.61s/it] 74%|███████▍  | 37/50 [25:34<10:41, 49.36s/it] 76%|███████▌  | 38/50 [26:10<09:03, 45.31s/it] 78%|███████▊  | 39/50 [26:31<06:59, 38.11s/it] 80%|████████  | 40/50 [27:08<06:16, 37.63s/it] 82%|████████▏ | 41/50 [27:20<04:29, 29.93s/it] 84%|████████▍ | 42/50 [28:01<04:26, 33.28s/it] 86%|████████▌ | 43/50 [28:52<04:31, 38.84s/it] 88%|████████▊ | 44/50 [30:00<04:44, 47.40s/it] 90%|█████████ | 45/50 [30:34<03:36, 43.38s/it] 92%|█████████▏| 46/50 [31:34<03:13, 48.40s/it] 94%|█████████▍| 47/50 [32:30<02:32, 50.77s/it] 96%|█████████▌| 48/50 [33:22<01:42, 51.12s/it] 98%|█████████▊| 49/50 [34:20<00:53, 53.12s/it]100%|██████████| 50/50 [35:09<00:00, 51.98s/it]100%|██████████| 50/50 [35:09<00:00, 42.20s/it]
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.82it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]
  0%|          | 0/50 [00:00<?, ?it/s]Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  2%|▏         | 1/50 [00:25<20:25, 25.02s/it]  4%|▍         | 2/50 [00:52<21:18, 26.63s/it]  6%|▌         | 3/50 [01:05<15:52, 20.26s/it]  8%|▊         | 4/50 [01:16<12:47, 16.68s/it] 10%|█         | 5/50 [01:28<11:17, 15.06s/it] 12%|█▏        | 6/50 [01:45<11:24, 15.55s/it] 14%|█▍        | 7/50 [02:05<12:15, 17.10s/it] 16%|█▌        | 8/50 [02:17<10:42, 15.31s/it] 18%|█▊        | 9/50 [02:26<09:05, 13.31s/it] 20%|██        | 10/50 [02:51<11:19, 17.00s/it] 22%|██▏       | 11/50 [03:21<13:45, 21.16s/it] 24%|██▍       | 12/50 [03:29<10:48, 17.06s/it] 26%|██▌       | 13/50 [03:37<08:44, 14.17s/it] 28%|██▊       | 14/50 [04:21<13:56, 23.25s/it] 30%|███       | 15/50 [04:42<13:10, 22.60s/it] 32%|███▏      | 16/50 [05:57<21:48, 38.49s/it] 34%|███▍      | 17/50 [06:00<15:13, 27.68s/it] 36%|███▌      | 18/50 [06:08<11:41, 21.93s/it] 38%|███▊      | 19/50 [06:20<09:43, 18.82s/it] 40%|████      | 20/50 [06:23<07:05, 14.17s/it] 42%|████▏     | 21/50 [06:43<07:39, 15.85s/it] 44%|████▍     | 22/50 [07:06<08:20, 17.88s/it] 46%|████▌     | 23/50 [07:23<07:57, 17.69s/it] 48%|████▊     | 24/50 [07:32<06:36, 15.24s/it] 50%|█████     | 25/50 [07:54<07:07, 17.11s/it] 52%|█████▏    | 26/50 [08:11<06:52, 17.18s/it] 54%|█████▍    | 27/50 [08:27<06:28, 16.90s/it] 56%|█████▌    | 28/50 [08:36<05:16, 14.37s/it] 58%|█████▊    | 29/50 [08:37<03:39, 10.45s/it] 60%|██████    | 30/50 [08:51<03:50, 11.55s/it] 62%|██████▏   | 31/50 [09:08<04:06, 12.99s/it] 64%|██████▍   | 32/50 [09:25<04:16, 14.27s/it] 66%|██████▌   | 33/50 [09:37<03:52, 13.66s/it] 68%|██████▊   | 34/50 [09:52<03:44, 14.04s/it] 70%|███████   | 35/50 [10:09<03:41, 14.74s/it] 72%|███████▏  | 36/50 [10:31<03:58, 17.05s/it] 74%|███████▍  | 37/50 [10:49<03:45, 17.34s/it] 76%|███████▌  | 38/50 [10:54<02:42, 13.56s/it] 78%|███████▊  | 39/50 [11:03<02:14, 12.27s/it] 80%|████████  | 40/50 [11:24<02:29, 14.93s/it] 82%|████████▏ | 41/50 [11:41<02:19, 15.47s/it] 84%|████████▍ | 42/50 [11:56<02:02, 15.29s/it] 86%|████████▌ | 43/50 [12:19<02:03, 17.62s/it] 88%|████████▊ | 44/50 [12:30<01:33, 15.61s/it] 90%|█████████ | 45/50 [12:46<01:19, 15.89s/it] 92%|█████████▏| 46/50 [13:10<01:13, 18.31s/it] 94%|█████████▍| 47/50 [13:53<01:17, 25.74s/it] 96%|█████████▌| 48/50 [14:16<00:49, 24.94s/it] 98%|█████████▊| 49/50 [14:32<00:22, 22.29s/it]100%|██████████| 50/50 [15:23<00:00, 30.62s/it]100%|██████████| 50/50 [15:23<00:00, 18.46s/it]
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.05it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  4.40it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.05it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.63it/s]
  0%|          | 0/50 [00:00<?, ?it/s]Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  2%|▏         | 1/50 [00:44<36:42, 44.95s/it]  4%|▍         | 2/50 [02:02<51:16, 64.09s/it]  6%|▌         | 3/50 [03:20<55:01, 70.25s/it]  8%|▊         | 4/50 [04:37<56:02, 73.10s/it] 10%|█         | 5/50 [04:59<40:56, 54.59s/it] 12%|█▏        | 6/50 [05:55<40:33, 55.32s/it] 14%|█▍        | 7/50 [06:59<41:33, 57.99s/it] 16%|█▌        | 8/50 [08:16<44:47, 63.98s/it] 18%|█▊        | 9/50 [09:33<46:35, 68.17s/it] 20%|██        | 10/50 [10:15<39:58, 59.95s/it] 22%|██▏       | 11/50 [10:44<32:47, 50.45s/it] 24%|██▍       | 12/50 [11:38<32:41, 51.61s/it] 26%|██▌       | 13/50 [12:47<35:03, 56.84s/it] 28%|██▊       | 14/50 [13:39<33:21, 55.59s/it] 30%|███       | 15/50 [14:50<34:58, 59.96s/it] 32%|███▏      | 16/50 [16:07<37:00, 65.31s/it] 34%|███▍      | 17/50 [17:25<37:57, 69.02s/it] 36%|███▌      | 18/50 [18:43<38:14, 71.70s/it] 38%|███▊      | 19/50 [20:01<38:00, 73.56s/it] 40%|████      | 20/50 [20:25<29:22, 58.74s/it] 42%|████▏     | 21/50 [21:37<30:17, 62.68s/it] 44%|████▍     | 22/50 [22:24<27:07, 58.14s/it] 46%|████▌     | 23/50 [23:42<28:47, 63.99s/it] 48%|████▊     | 24/50 [24:37<26:30, 61.19s/it] 50%|█████     | 25/50 [25:12<22:14, 53.38s/it] 52%|█████▏    | 26/50 [25:58<20:27, 51.15s/it] 54%|█████▍    | 27/50 [26:48<19:28, 50.82s/it] 56%|█████▌    | 28/50 [27:45<19:19, 52.71s/it] 58%|█████▊    | 29/50 [28:17<16:19, 46.64s/it] 60%|██████    | 30/50 [29:35<18:39, 55.96s/it] 62%|██████▏   | 31/50 [30:53<19:47, 62.52s/it] 64%|██████▍   | 32/50 [31:40<17:19, 57.75s/it] 66%|██████▌   | 33/50 [32:29<15:37, 55.13s/it] 68%|██████▊   | 34/50 [33:20<14:26, 54.13s/it] 70%|███████   | 35/50 [33:54<12:00, 48.03s/it] 72%|███████▏  | 36/50 [35:09<13:03, 55.97s/it] 74%|███████▍  | 37/50 [36:08<12:21, 57.06s/it] 76%|███████▌  | 38/50 [36:59<11:02, 55.20s/it] 78%|███████▊  | 39/50 [38:10<10:58, 59.89s/it] 80%|████████  | 40/50 [39:16<10:17, 61.79s/it] 82%|████████▏ | 41/50 [39:26<06:55, 46.14s/it] 84%|████████▍ | 42/50 [40:14<06:13, 46.75s/it] 86%|████████▌ | 43/50 [40:25<04:12, 36.05s/it] 88%|████████▊ | 44/50 [40:35<02:49, 28.26s/it] 90%|█████████ | 45/50 [41:49<03:29, 41.95s/it] 92%|█████████▏| 46/50 [41:57<02:07, 31.89s/it] 94%|█████████▍| 47/50 [42:32<01:37, 32.61s/it] 96%|█████████▌| 48/50 [43:23<01:16, 38.11s/it] 98%|█████████▊| 49/50 [43:46<00:33, 33.61s/it]100%|██████████| 50/50 [43:59<00:00, 27.49s/it]100%|██████████| 50/50 [43:59<00:00, 52.79s/it]
/home/seungonk/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]
  0%|          | 0/50 [00:00<?, ?it/s]Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Expanding inputs for image tokens in LLaVa-NeXT should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  2%|▏         | 1/50 [00:46<38:18, 46.91s/it]  4%|▍         | 2/50 [01:27<34:30, 43.14s/it]  6%|▌         | 3/50 [02:03<31:22, 40.06s/it]  8%|▊         | 4/50 [03:02<36:19, 47.38s/it] 10%|█         | 5/50 [03:33<31:05, 41.46s/it] 12%|█▏        | 6/50 [04:25<32:59, 44.99s/it] 14%|█▍        | 7/50 [05:03<30:43, 42.86s/it] 16%|█▌        | 8/50 [05:54<31:41, 45.28s/it] 18%|█▊        | 9/50 [06:21<27:01, 39.56s/it] 20%|██        | 10/50 [07:13<28:56, 43.41s/it] 22%|██▏       | 11/50 [08:03<29:35, 45.52s/it] 24%|██▍       | 12/50 [08:54<29:51, 47.14s/it] 26%|██▌       | 13/50 [09:34<27:44, 45.00s/it] 28%|██▊       | 14/50 [10:23<27:40, 46.11s/it] 30%|███       | 15/50 [11:06<26:26, 45.34s/it] 32%|███▏      | 16/50 [11:11<18:49, 33.23s/it] 34%|███▍      | 17/50 [11:46<18:35, 33.79s/it] 36%|███▌      | 18/50 [12:12<16:45, 31.43s/it] 38%|███▊      | 19/50 [12:42<15:57, 30.90s/it] 40%|████      | 20/50 [12:54<12:33, 25.12s/it] 42%|████▏     | 21/50 [13:21<12:30, 25.90s/it] 44%|████▍     | 22/50 [13:49<12:23, 26.55s/it] 46%|████▌     | 23/50 [14:19<12:22, 27.50s/it] 48%|████▊     | 24/50 [14:35<10:27, 24.12s/it] 50%|█████     | 25/50 [15:13<11:41, 28.05s/it] 52%|█████▏    | 26/50 [16:02<13:45, 34.40s/it] 54%|█████▍    | 27/50 [16:37<13:14, 34.56s/it] 56%|█████▌    | 28/50 [17:39<15:42, 42.86s/it] 58%|█████▊    | 29/50 [18:37<16:35, 47.43s/it] 60%|██████    | 30/50 [19:13<14:42, 44.14s/it] 62%|██████▏   | 31/50 [19:33<11:40, 36.88s/it] 64%|██████▍   | 32/50 [19:41<08:24, 28.06s/it] 66%|██████▌   | 33/50 [20:13<08:18, 29.32s/it] 68%|██████▊   | 34/50 [20:26<06:30, 24.39s/it] 70%|███████   | 35/50 [20:41<05:22, 21.48s/it] 72%|███████▏  | 36/50 [21:06<05:15, 22.51s/it] 74%|███████▍  | 37/50 [21:22<04:29, 20.73s/it] 76%|███████▌  | 38/50 [22:01<05:13, 26.10s/it] 78%|███████▊  | 39/50 [22:19<04:21, 23.75s/it] 80%|████████  | 40/50 [22:58<04:41, 28.20s/it] 82%|████████▏ | 41/50 [23:13<03:40, 24.45s/it] 84%|████████▍ | 42/50 [23:25<02:43, 20.48s/it] 86%|████████▌ | 43/50 [23:39<02:09, 18.56s/it] 88%|████████▊ | 44/50 [24:00<01:55, 19.27s/it] 90%|█████████ | 45/50 [24:07<01:19, 15.84s/it] 92%|█████████▏| 46/50 [24:47<01:32, 23.04s/it] 94%|█████████▍| 47/50 [25:54<01:48, 36.29s/it] 96%|█████████▌| 48/50 [26:32<01:13, 36.65s/it] 98%|█████████▊| 49/50 [27:05<00:35, 35.52s/it]100%|██████████| 50/50 [27:29<00:00, 32.06s/it]100%|██████████| 50/50 [27:29<00:00, 32.99s/it]
